{
    "collab_server" : "",
    "contents" : "# How to download a file using a URL\n\nlibrary(downloader) \nurl <- \"https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv\"\nfilename <- \"femaleMiceWeights.csv\" \ndownload(url, destfile=filename)\n\n#\n\nfemaleMW = read.csv(\"femaleMiceWeights.csv\")\nstr(femaleMW)\nfemaleMW[12,2]\nfemaleMW$Bodyweight[11]\nlength(femaleMW$Bodyweight)\n\nmean(femaleMW[femaleMW$Diet==\"hf\",]$Bodyweight)\n\nset.seed(1)\nsample(13:24, 1)\nfemaleMW$Bodyweight[16]\n\n# dplyr\ninstall.packages(\"dplyr\")\nlibrary(dplyr)\n\ninstall.packages(\"downloader\")\nlibrary(downloader)\nurl=\"https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/msleep_ggplot2.csv\"\nfilename <- basename(url)\ndownload(url,filename)\n\ndat=read.csv(\"msleep_ggplot2.csv\")\nclass(dat)\n\ndat = read.csv(\"femaleMiceWeights.csv\")\nstr(dat)\n\n# Random VAriables Exercise #1\ndat=read.csv(\"femaleControlsPopulation.csv\")\n\nsummary(dat)\nset.seed(1)\nsam=sample(dat$Bodyweight, 5)\nabs(mean(sam)-mean(dat$Bodyweight))\n\nset.seed(5)\nsam=sample(dat$Bodyweight, 5)\nabs(mean(sam)-mean(dat$Bodyweight))\n\n# Conclusion: Abs diff using 2 different samples in a random variable\n\n# Null distributions exeercises\n\nset.seed(1)\nn=10000\navgs=vector(\"numeric\",n)\nfor (i in 1:n){ \n  avgs[i]=mean(sample(dat$Bodyweight,50))\n}\n\nsum(abs(avgs-mean(dat$Bodyweight))>1)/n\n\n\n#\n\ninstall.packages(\"gapminder\")\nlibrary(gapminder)\ndata(\"gapminder\")\nhead(gapminder)\n\nx=gapminder[gapminder$year==1952,]\nhead(x)\nsummary(x)\nhist(x$lifeExp)\n\n# We can compute F in two ways: the simplest way is to type mean(x <= a). \n# This calculates the number of values in x which are less than or equal a, \n# divided by the total number of values in x, in other words the proportion of values \n# less than or equal to a.\n\nmean(x$lifeExp <= 40)\n\nmean(x$lifeExp <= 60) - mean(x$lifeExp <= 40)\n\nprop = function(q) {\n  mean(x$lifeExp <= q)\n}\nclass(prop)\nprop(40)\n\nqs = seq(from=min(x$lifeExp), to=max(x$lifeExp), length=20)\nprops=sapply(qs,prop)\n\nplot(qs,props)\n\n# Or\n\nprops = sapply(qs, function(q) mean(x$lifeExp <= q))\n\n#Last was an inline function or anonymous\n\n# Compare with the built in function\nplot(ecdf(x$lifeExp))\n\n#\ndat=read.csv(\"femaleControlsPopulation.csv\")\nsummary(dat)\n\nset.seed(1)\n\navgs5=vector(\"numeric\", 1000)\nn=1000\nfor (i in 1:n){\n  avgs5[i]=mean(sample(dat$Bodyweight,5))\n}\navgs50=vector(\"numeric\",1000)\nfor (i in 1:n){\n  avgs50[i]=mean(sample(dat$Bodyweight,50))\n}\n\nhist(avgs5)\nhist(avgs50)\n\nmean(avgs50<=25)-mean(avgs50<=23)\n\nz23=(23-23.9)/0.43\nz25=(25-23.9)/0.43\n\nz25-z23\n\npnorm(25,23.9,0.43)-pnorm(23,23.9,0.43)\n# same as above:\npnorm(z25)-pnorm(z23)\n# basically the Z is normalized to Normal(0,1)\n\n#\n\ndat=read.csv(\"mice_pheno.csv\")\ndat=na.omit(dat)\nstr(dat)\n# MALES\nmalechow=dat[dat$Sex==\"M\" & dat$Diet==\"chow\",]\nxmean=mean(dat[dat$Sex==\"M\" & dat$Diet==\"chow\",]$Bodyweight)\nxsd=sd(dat[dat$Sex==\"M\" & dat$Diet==\"chow\",]$Bodyweight)\n\nset.seed(1)\nX=sample(malechow$Bodyweight, 25)\nXmean=mean(X)\n\n# Now males HF\nmalehf=dat[dat$Sex==\"M\" & dat$Diet==\"hf\",]\nymean=mean(malehf$Bodyweight)\n\ninstall.packages(\"rafalib\")\nlibrary(rafalib)\nysd=popsd(malehf$Bodyweight)\n\nset.seed(1)\nY=sample(malehf$Bodyweight, 25)\nYmean=mean(Y)\n\n(ymean-xmean)-(Ymean-Xmean)\n\n# FEMALES\nfemalechow=dat[dat$Sex==\"F\" & dat$Diet==\"chow\",]\nxmean=mean(femalechow$Bodyweight)\nxsd=sd(femalechow$Bodyweight)\n\nset.seed(1)\nX=sample(femalechow$Bodyweight, 25)\nXmean=mean(X)\n\n# Now females HF\nfemalehf=dat[dat$Sex==\"F\" & dat$Diet==\"hf\",]\nymean=mean(femalehf$Bodyweight)\n\nysd=popsd(femalehf$Bodyweight)\n\nset.seed(1)\nY=sample(femalehf$Bodyweight, 25)\nYmean=mean(Y)\n\nabs((ymean-xmean)-(Ymean-Xmean))\n\n(ymean-xmean)\n(Ymean-Xmean)\n#\n\n# CTL exercises\ndat <- na.omit( read.csv(\"mice_pheno.csv\"))\nstr(dat)\n\nstr(malechow)\ny=malechow$Bodyweight\nstr(y)\nymean=mean(y)\nysd=popsd(y)\nc(ymean, ysd)\n\nmean(y>ymean-ysd & y<=ymean+ysd)\n\nmean(y>ymean-2*ysd & y<=ymean+2*ysd)\n\nmean(y>ymean-3*ysd & y<=ymean+3*ysd)\n\n\n#\navgs <- replicate(10000, mean( sample(y, 25)))\nmypar(1,2)\nhist(avgs)\nqqnorm(avgs)\nqqline(avgs)\n\nmean(avgs)\npopsd(avgs)\n\n#CLT exercice 1\n# Dices\n\ndat=read.csv(\"femaleMiceWeights.csv\")\n\nmypar()\navgs=vector(\"numeric\",10000)\n\nmypar(1,2)\nN=10000  #Number of samples\nn=100  # Number of dice\nset.seed(1)\n\navgs=replicate(N,mean(sample(1:6, n, replace=TRUE)==6))\n\nhist(avgs)\np1=mean(avgs)\nsd1=popsd(avgs)\n\n# z = (mean(x==6) - p) / sqrt(p*(1-p)/n) \n\np=1/6\nsd=sqrt(p*(1-p)/100)\n\nz=(avgs-p)/sd\nqqnorm(z)\nabline(0,1)#confirm it's well approximated with normal distribution\n\nmean(abs(z)>2)\n\nmean(z)\n\n# Code from the solution\nset.seed(1)\nn <- 100\nsides <- 6\np <- 1/sides\nzs <- replicate(10000,{\n  x <- sample(1:sides,n,replace=TRUE)\n  (mean(x==6) - p) / sqrt(p*(1-p)/n)\n}) \nqqnorm(zs)\nabline(0,1)#confirm it's well approximated with normal distribution\nmean(abs(zs) > 2)\n# End code from Solution\ninstall.packages(\"rafalib\")\nlibrary(rafalib)\n\nmypar(2,2)\n\nset.seed(1)\np <- 0.01\nn <- 100\nzs <- replicate(10000,{\n  x <- sample(1:6,n,replace=TRUE)\n  (mean(x==6) - p) / sqrt(p*(1-p)/n)\n}) \nqqnorm(zs)\nabline(0,1)#confirm it's well approximated with normal distribution\nhist(zs)\n\n#It sucks, solution is a hidden parameter sides\n\n\nps <- c(0.5,0.5,0.01,0.01)\nns <- c(5,30,30,100)\nlibrary(rafalib)\nmypar(4,2)\nfor(i in 1:4){\n  p <- ps[i]\n  sides <- 1/p\n  n <- ns[i]\n  zs <- replicate(10000,{\n    x <- sample(1:sides,n,replace=TRUE)\n    (mean(x==1) - p) / sqrt(p*(1-p)/n)\n  }) \n  hist(zs,nclass=7)\n  qqnorm(zs)\n  abline(0,1)\n}\n\n######################\n\nrm(list=ls())\n\ndat=read.csv(\"femaleMiceWeights.csv\")\nX=dat[dat$Diet==\"chow\",]$Bodyweight\nY=dat[dat$Diet==\"hf\",]$Bodyweight\nXavg=mean(X)\nXavg\n\nXvar=var(X)\nXvar\nXsd=sqrt(Xvar)\nXsd\n# that is the same as sd(X)\n\nsd1=sd(X)*sqrt((length(X)-1)/(length(X)))\nmean1=mean(X)\nz=2/sd1\nz\n1-pnorm(z)\n2*(1-pnorm(z))\n\n# Exerc 7\nw=sqrt(length(X))*(2)/sd(X)\nsd(X)\nlength(X)\nw\n2*(1-pnorm(w))\n\n# Exerc 8\n# Under the null Hypotesis\n# should be muX=muY\n# SE(avgX-avgY)=sqrt(var(X)/12+var(Y)/12))\n# This is the standard deviation of this statitistic \n# also known as standard error or SE.\n#\nlength(X)\nlength(Y)\nvarX=var(X)\nvarY=var(Y)\nserror=sqrt(varX/length(X)+varY/length(Y))\nserror\n\n# T-stats\n# T-stat is realtive to 1 sample\n# If you consider many samples you end up with T-Distribution\nmean(Y)-mean(X)\ntstat=(mean(Y)-mean(X))/serror\ntstat\n# The larger the absolute value of the t-value, the smaller the p-value, \n# and the greater the evidence against the null hypothesis\n2*(1-pnorm(tstat))\n\n1 - pt(3,df=3)\n1 - pt(3,df=15)\n1 - pt(3,df=30)\n1 - pnorm(3)\n\n#t.test calculates all the values\nt.test(X)\nt.test(Y)\n\nt.test(Y,X) # Computes the T-value and Degrees of freedom and p-value\n\n# the test based on the CLT approximation is more likely to incorrectly reject the\n# null hypothesis (a false positive), while the t-distribution is more likely to incorrectly accept the null\n# hypothesis (false negative)\n\n# Week 3\nlibrary(downloader)\nurl <- \"https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt\"\nfilename <- basename(url)\ndownload(url, destfile=filename)\nbabies <- read.table(\"babies.txt\", header=TRUE)\n\nbwt.nonsmoke=babies[babies$smoke==0,]$bwt\nbwt.smoke=babies[babies$smoke==1,]$bwt\n\nlibrary(rafalib)\nmean(bwt.nonsmoke)-mean(bwt.smoke)\npopsd(bwt.nonsmoke)\npopsd(bwt.smoke)\n\nset.seed(1)\ndat.ns=sample(bwt.nonsmoke, 25)\ndat.s=sample(bwt.smoke, 25)\n\nt.test(dat.ns, dat.s)\ntval=2.1209\n\n# Solution\n\nN=25\nset.seed(1)\ndat.ns <- sample(bwt.nonsmoke , N)\ndat.s <- sample(bwt.smoke , N)\n\nX.ns <- mean(dat.ns)\nsd.ns <- sd(dat.ns)\n\nX.s <- mean(dat.s)\nsd.s <- sd(dat.s)\n\nsd.diff <- sqrt(sd.ns^2/N+sd.s^2/N)\ntval <- (X.ns - X.s)/sd.diff\ntval\n\n#########\n\n2*pnorm(-abs(tval))\n\n# Confidence interval of 99%\n# Find the t-stat\ntval99=abs(qnorm(0.01/2))\ntval99  # represents the number of standard deviations from the mean\n\nsd.diff\n\n# Lets multiply by the standard deviation to find the value to add to the mean\ntval99*sd.diff\n# 12.0478\n# Interval will be:\nX.ns - X.s  +- tval99*sd.diff\n\n####\nqtval99=abs(qt(0.01/2,2*(N-2)))\nqtval99  # represents the number of standard deviations from the mean\n\nsd.diff\n\n# Lets multiply by the standard deviation to find the value to add to the mean\nqtval99*sd.diff\n\n# 12.56783\n\nN=5\nset.seed(1)\ndat.ns <- sample(bwt.nonsmoke , N)\ndat.s <- sample(bwt.smoke , N)\n\nt.test(dat.ns, dat.s)\n\n#\n# Power:\n# Probability of rejecting the null hipotesis when the alternative is true.\n#\n\nlibrary(rafalib)\nmean(bwt.nonsmoke)-mean(bwt.smoke)\npopsd(bwt.nonsmoke)\npopsd(bwt.smoke)\n\n\nN=5    # sample size\nalpha=0.05  # Cutoff to reject H0\nB=10000  # No. of times we repeat the sample\n\nreject<-function(N, alpha=0.01){\n  dat.ns <- sample(bwt.nonsmoke , N)\n  dat.s <- sample(bwt.smoke , N)\n  t.test(dat.ns, dat.s)$p.value < alpha\n}\nreject(5)\n\nset.seed(1)\nrejections<-replicate(B, reject(N))\nmean(rejections)\n# 0.0984\n\nNs<-c(30, 60, 90, 120)\nset.seed(1)\n\npower<-sapply(Ns, function(N){\n  rejections<-replicate(B, reject(N))\n  mean(rejections)\n  }\n)\n\nplot(Ns, power, type=\"b\")\npower\ntable(power, Ns)\n\n# Monte Carlo simulations\nset.seed(1)\nX<-rnorm(5)\nt=sqrt(5)*mean(X)/sd(X)\nt\n\n#Monte Carlo Exercise 2\n\nmytstat<-function(){\n  X<-rnorm(5)\n  sqrt(5)*mean(X)/sd(X) > 2\n}\n\nset.seed(1)\nresult<-replicate(1000, mytstat())\nmean(result)\nhead(result)\n\n\n# Solution\nset.seed(1)\nN <- 5\nB<- 100\n\ntstats <- replicate(B,{\n  X <- rnorm(N)\n  sqrt(N)*mean(X)/sd(X)\n})\nmean(tstats>2)\n##############\n\n# Monte Carlo Exercise 3\nB=100; ps = seq(1/(B+1), 1-1/(B+1),len=B)\nN<-50\n\n#### Solution\n\nlibrary(rafalib)\nmypar(3,2)\n\nNs<-seq(5,30,5)\nB <- 1000\nmypar(3,2)\nLIM <- c(-4.5,4.5)\nfor(N in Ns){\n  ts <- replicate(B, {\n    X <- rnorm(N)\n    sqrt(N)*mean(X)/sd(X)\n  })\n  ps <- seq(1/(B+1),1-1/(B+1),len=B)\n  qqplot(qt(ps,df=N-1),ts,main=N,\n         xlab=\"Theoretical\",ylab=\"Observed\",\n         xlim=LIM, ylim=LIM)\n  abline(0,1)\n} \n######\n\n# Monte Carlo Exercise 4\n\nlibrary(rafalib)\nmypar(3,2)\n\nNs<-seq(5,30,5)\nB <- 1000\nmypar(3,2)\nLIM <- c(-4.5,4.5)\nset.seed(1)\nfor(N in Ns){\n  ts <- replicate(B, {\n    X <- rnorm(N,0,1)\n    Y <- rnorm(N,0,1)\n#    (mean(X)-mean(Y))/sqrt(var(X)/N+var(Y)/N)\n    t.test(X,Y,var.equal = TRUE)$statistic\n  })\n  ps <- seq(1/(B+1),1-1/(B+1),len=B)\n  qqplot(qt(ps,df=2*N-2),ts,main=N,\n#  qqnorm(ts,main=N,\n                xlab=\"Theoretical\",ylab=\"Observed\",\n         xlim=LIM, ylim=LIM)\n  abline(0,1)\n} \n\n# Monte Carlo Exercise 5\n\nlibrary(rafalib)\nmypar(3,2)\n\nNs<-seq(5,30,5)\nNs=c(1000)\nB <- 1000\nmypar(1,1)\nLIM <- c(-4.5,4.5)\nset.seed(1)\n\nfor(N in Ns){\n  ts <- replicate(B, {\n    X <- sample(c(-1,1), N, replace=TRUE)\n    sqrt(N)*mean(X)/sd(X)\n  })\n  ps <- seq(1/(B+1),1-1/(B+1),len=B)\n  qqplot(qt(ps,df=N-1),ts,main=N,\n         xlab=\"Theoretical\",ylab=\"Observed\",\n         xlim=LIM, ylim=LIM)\n  abline(0,1)\n} \n\n# Monte Carlo Exercise 7\n\n\nlibrary(rafalib)\nmypar(3,2)\n\nNs<-seq(5,30,5)\nNs<-c(5, 10, 50, 1000, 10000, 20000)\nB <- 1000\nmypar(3,2)\nLIM <- c(-4.5,4.5)\n\nset.seed(1)\nmn.sd<-sapply(Ns,function(N){\n  ts <- replicate(B, {\n    X <- rnorm(N)\n    #    sqrt(N)*median(X)/sd(X)\n    mean(X)\n  })\n    sd(ts)\n})\nset.seed(1)\nmd.sd<-sapply(Ns, function(N){\n  ts <- replicate(B, {\n    X <- rnorm(N)\n    #    sqrt(N)*median(X)/sd(X)\n    median(X)\n  })\n  sd(ts)\n})\n\nset.seed(1)\nmd.mean<-sapply(Ns, function(N){\n  ts <- replicate(B, {\n    X <- rnorm(N)\n    #    sqrt(N)*median(X)/sd(X)\n    median(X)\n  })\n  mean(ts)\n})\n\nmn.sd\n#[1] 0.463164960 0.307540795 0.142648147 0.031244522 0.009817387 0.006968280\nmd.sd\n#[1] 0.541248504 0.354307837 0.175427479 0.039361979 0.012388655 0.008616991\nmd.sd-mn.sd\n#[1] 0.078083544 0.046767042 0.032779332 0.008117457 0.002571268 0.001648711\n1/sqrt(Ns)\n#[1] 0.447213595 0.316227766 0.141421356 0.031622777 0.010000000 0.007071068\nmd.sd\nmd.mean\n\n### Solution: Monte Carlo exercise 7 \n\nset.seed(1)\nNs <- seq(5,45,5)\nlibrary(rafalib)\nmypar(3,3)\nfor(N in Ns){\n  medians <- replicate(10000, median ( rnorm(N) ) )\n  title <- paste(\"N=\",N,\", avg=\",round( mean(medians), 2) , \", \n                 sd*sqrt(N)=\", round( sd(medians)*sqrt(N),2) )\n  qqnorm(medians, main = title )\n  qqline(medians)\n}\n\n##there is an asymptotic result that says SD is sqrt(N*4*dnorm(0)^2)\n\n##########\n# Permutations Exercise 1\nlibrary(rafalib)\n\nbabies <- read.table(\"babies.txt\", header=TRUE)\nbwt.nonsmoke <- babies[babies$smoke==0,]$bwt \nbwt.smoke <- babies[babies$smoke==1,]$bwt \n\n\nN=10\nset.seed(1)\nnonsmokers <- sample(bwt.nonsmoke , N)\nsmokers <- sample(bwt.smoke , N)\nobs <- mean(smokers) - mean(nonsmokers)\n\n# reshufle the data\n\ndat <- c(smokers,nonsmokers)\n\nset.seed(1)\nnull<-replicate(1000, {\n  shuffle <- sample( dat )\n  smokersstar <- shuffle[1:N]\n  nonsmokersstar <- shuffle[(N+1):(2*N)]\n  mean(smokersstar)-mean(nonsmokersstar)\n})\nmypar(1,1)\nhist(null)\nabline(v=obs, col=\"red\", lwd=2)\nmean(null<=obs)\n\n# The proportion of permutaions with larger difference\n(sum(abs(null) > abs(obs))+1) / (length(null)+1)\n\n\n# Permutations Exercise 2\n\nN=10\nset.seed(1)\nnonsmokers <- sample(bwt.nonsmoke , N)\nsmokers <- sample(bwt.smoke , N)\nobs <- median(smokers) - median(nonsmokers)\n\n# reshufle the data\n\ndat <- c(smokers,nonsmokers)\n\nset.seed(1)\nnull<-replicate(1000, {\n  shuffle <- sample( dat )\n  smokersstar <- shuffle[1:N]\n  nonsmokersstar <- shuffle[(N+1):(2*N)]\n  median(smokersstar)-median(nonsmokersstar)\n})\nmypar(1,1)\nhist(null)\nabline(v=obs, col=\"red\", lwd=2)\nmean(null<=obs)\n\n# The proportion of permutaions with larger difference\n(sum(abs(null) > abs(obs))+1) / (length(null)+1)\n\n# Association Tests Exercise 1 and 2\n\nd = read.csv(\"assoctest.csv\")\nhead(d)\n\ntable(d$allele)\ntable(d$case)\nt=table(d$allele, d$case)\nt\nchisq.test(t)\nfisher.test(t)\n\n# Chapter 4\n\nload(\"skew.RData\")\ndim(dat)\npar(mfrow = c(3,3))\nfor (i in 1:9) {\n   qqnorm(dat[,i])\n}\npar(mfrow=c(1,2))\nhist(dat[,4])\nhist(dat[,9])\nstr(dat)\n\n####\nhead(InsectSprays)\nstr(InsectSprays)\nsummary(InsectSprays)\nt=split(InsectSprays, InsectSprays$spray)\n\npar(mfrow=c(1,1))\n\nboxplot(InsectSprays$count ~ InsectSprays$spray)\n\n###\ninstall.packages(\"UsingR\")\nlibrary(dplyr)\ndata(nym.2002, package=\"UsingR\")\nsummary(nym.2002)\n\n#par(mfrow=c(1,1,2,3))\nlayout(matrix(c(1,1,2,3),2,2,byrow=TRUE))\n\nboxplot(nym.2002$time ~ nym.2002$gender)\nhist(nym.2002[nym.2002$gender==\"Female\",]$time, main=\"Female\")\nhist(nym.2002[nym.2002$gender==\"Male\",]$time, main=\"Male\")\n\n# Solution\n\nmypar(1,3)\nmales <- filter(nym.2002, gender==\"Male\") %>% select(time) %>% unlist\nfemales <- filter(nym.2002, gender==\"Female\") %>% select(time) %>% unlist\nboxplot(females, males)\nhist(females,xlim=c(range( nym.2002$time)))\nhist(males,xlim=c(range( nym.2002$time)))\n\n### Scatter plots\ndata(\"father.son\", package=\"UsingR\")\n\nx=father.son$fheight\ny=father.son$sheight\n\nmypar(1,1)\nplot(x,y, xlab=\"Father's height in inches\",ylab=\"Son's height in inches\")\n\nboxplot(split(y,round(x)))\n\nprint(mean(y[round(x)==72]))\n\nx=(x-mean(x))/sd(x)\ny=(y-mean(y))/sd(y)\n# trick round(x*4)/4 to squash the values into quartiles\nmeans=(tapply(y, round(x*4)/4, mean))\n# turn into numbers the names of the vector to display in the plot\nfatherheights=as.numeric(names(means))\nplot(fatherheights, means, ylab=\"average of strata son height\")\nabline(0,cor(x,y))\n\n# this is true for normal disributed data\n\n# if is not normal distributed the correlation gives a wrong indication\n# example\nset.seed(1)\na=rnorm(100); a[1]=25\nb=rnorm(100); b[1]=26\nplot(a,b, main=paste(\"correlation=\", round(cor(a,b), digits = 2)))\n# coreelation in the chart is 0.88\ncor(a,b, method = \"spearman\")\n# 0.05\n# The added points make the correlation very high altough there is no correlation\n# all this because the data is not normal distributed\n\n## Exercises\nsummary(nym.2002)\nmales=subset(nym.2002, gender==\"Male\")\nfemales=subset(nym.2002, gender==\"Female\")\n\n# default correlation in R is Pearson\ncor(males$age, males$time)\n# 0.2432273\ncor(females$age, females$time)\n#0.2443156\n\nmypar(1,2)\nplot(males$age%/%5*5, males$time)\nboxplot(split(males$time, males$age%/%5*5))\nr=round(tapply(males$time, males$age%/%5*5, mean))\nr[i]-r[i-1]\n\n# Symmetry\ntime = sort(nym.2002$time)\ntime[1]/median(time)\ntime[1000]/median(time)\n\n# compare\nplot(time/median(time), ylim=c(1/4,4))\nabline(h=c(1/2,1,2))\n\nplot(log2(time/median(time)),ylim=c(-2,2))\nabline(h=-1:1)\n# We use logs for chart symmetry around 0\n\n# Robust Summaries\nmypat(1,1)\ndata(\"ChickWeight\")\nhead(ChickWeight)\nplot( ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet)\n\nchick = reshape(ChickWeight, idvar=c(\"Chick\",\"Diet\"), timevar=\"Time\",\n                direction=\"wide\")\nhead(chick)\n\nchick=na.omit(chick)\n\nday4=chick$weight.4\nday4out=c(day4, 3000)\nday4out[46]\n# how sensitive the mean is to outliers\nmean(day4out)/mean(day4)\n# median in contrast is not sensitive\nmedian(day4out)/median(day4)\n# how sensitive is the Standard Deviation to the outliers\nsd(day4out)/sd(day4)\n# what is the MAD (Median Absolute Deviation)\nmad(day4out)/mad(day4)\n\nday21=chick$weight.21\nday21out=c(day21, 3000)\ncor(day4,day21)\n\ncor(day4out,day21out)/cor(day4,day21)\n\n\n# Last at last ...\n# Mann-Whitney-Wilcoxon exercises\nx=subset(chick, chick$Diet==1)$weight.4\nhead(x)\ny=subset(chick, chick$Diet==4)$weight.4\n\nt.test(x,y)\n\nwilcox.test(x,y)\n# Add an outlier to x\nx.out=c(x,200)\nt.test(x.out, y)$p.value\nwilcox.test(x.out,y)$p.value\n\n# Exercise 3\n# investigate possible downside to Wilcox-Mann-Witney test statitic\nlibrary(rafalib)\nmypar(1,3)\nboxplot(x,y)\nboxplot(x,y+10)\nboxplot(x,y+100)\n\nt.test(x,y+10)$statistic - t.test(x,y+100)$statistic\n\n# Now Wilcox\n# Because the Wilcoxon works on ranks, once the two groups show complete separation, \n# that is all points from group 'y' are above all points from group 'x', \n# the statistic will not change, regardless of how large the difference grows.\n\n# Likewise, the p-value has a minimum value, regardless of how far apart the groups are.\n# This means that the Wilcoxon test can be considered less powerful than the t-test in \n# certain contexts. \n\nz=c(1,2,3)\nw=c(4,5,6)\nwilcox.test(z,w)$p.value\n\nv=c(400,500,600)\nwilcox.test(z,v)$p.value\n",
    "created" : 1462107652637.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1359568501",
    "id" : "2BCBDACF",
    "lastKnownWriteTime" : 1463435953,
    "last_content_update" : 1463435953801,
    "path" : "~/Desktop/edX/Data_Analysis_for_Life_Sciences_1/Project1/code.R",
    "project_path" : "code.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}